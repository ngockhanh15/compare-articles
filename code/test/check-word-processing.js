/**
 * Ki·ªÉm tra xem ch∆∞∆°ng tr√¨nh c√≥ t·∫°o bigram/n-gram hay kh√¥ng
 */

const vietnameseStopwordService = require('../be/services/VietnameseStopwordService');
const { TextHasher } = require('../be/utils/TreeAVL');

class WordProcessingChecker {
  constructor() {
    this.initialized = false;
  }

  async initialize() {
    if (!this.initialized) {
      console.log('üîß Kh·ªüi t·∫°o Vietnamese Stopword Service...');
      await vietnameseStopwordService.initialize();
      this.initialized = true;
      console.log('‚úÖ Kh·ªüi t·∫°o ho√†n t·∫•t!');
    }
  }

  async checkWordProcessing() {
    await this.initialize();
    
    console.log('üîç KI·ªÇM TRA C√ÅCH X·ª¨ L√ù T·ª™ TRONG CH∆Ø∆†NG TR√åNH');
    console.log('='.repeat(60));
    
    const testText = "Th·ªÉ thao l√† m√¥n ∆∞a th√≠ch c·ªßa m·ªçi ng∆∞·ªùi t√¥i c≈©ng kh√¥ng ƒë·∫∑c bi·ªát";
    
    console.log('üìù VƒÉn b·∫£n test:', testText);
    
    // 1. Ki·ªÉm tra extractMeaningfulWords
    console.log('\n1Ô∏è‚É£ EXTRACT MEANINGFUL WORDS:');
    const meaningfulWords = vietnameseStopwordService.extractMeaningfulWords(testText);
    console.log('Meaningful words:', meaningfulWords);
    console.log('S·ªë t·ª´:', meaningfulWords.length);
    
    // 2. Ki·ªÉm tra createWordHashes
    console.log('\n2Ô∏è‚É£ CREATE WORD HASHES:');
    const wordHashes = TextHasher.createWordHashes(testText, true);
    console.log('Word hashes count:', wordHashes.length);
    console.log('Sample hashes:');
    wordHashes.slice(0, 5).forEach((hash, index) => {
      console.log(`  ${index + 1}. Word: "${hash.word}" | Hash: ${hash.hash.substring(0, 12)}... | Method: ${hash.method}`);
    });
    
    // 3. Ki·ªÉm tra splitByStopwords (chunks)
    console.log('\n3Ô∏è‚É£ SPLIT BY STOPWORDS (CHUNKS):');
    const chunks = vietnameseStopwordService.splitByStopwords(testText, {
      minChunkLength: 2,
      maxChunkLength: 5,
      preserveStopwords: false
    });
    console.log('Chunks count:', chunks.length);
    chunks.forEach((chunk, index) => {
      console.log(`  Chunk ${index + 1}: "${chunk.text}" (${chunk.meaningfulWordCount} meaningful words)`);
    });
    
    // 4. T·∫°o bigram th·ªß c√¥ng ƒë·ªÉ so s√°nh
    console.log('\n4Ô∏è‚É£ BIGRAM TH·ª¶ C√îNG (ƒê·ªÇ SO S√ÅNH):');
    const bigrams = this.createBigrams(meaningfulWords);
    console.log('Bigrams:', bigrams);
    console.log('S·ªë bigram:', bigrams.length);
    
    // 5. T·∫°o trigram th·ªß c√¥ng
    console.log('\n5Ô∏è‚É£ TRIGRAM TH·ª¶ C√îNG (ƒê·ªÇ SO S√ÅNH):');
    const trigrams = this.createTrigrams(meaningfulWords);
    console.log('Trigrams:', trigrams);
    console.log('S·ªë trigram:', trigrams.length);
    
    return {
      meaningfulWords,
      wordHashes,
      chunks,
      bigrams,
      trigrams
    };
  }

  // T·∫°o bigram t·ª´ danh s√°ch t·ª´
  createBigrams(words) {
    const bigrams = [];
    for (let i = 0; i < words.length - 1; i++) {
      bigrams.push(`${words[i]}_${words[i + 1]}`);
    }
    return bigrams;
  }

  // T·∫°o trigram t·ª´ danh s√°ch t·ª´
  createTrigrams(words) {
    const trigrams = [];
    for (let i = 0; i < words.length - 2; i++) {
      trigrams.push(`${words[i]}_${words[i + 1]}_${words[i + 2]}`);
    }
    return trigrams;
  }

  // So s√°nh 2 c√¢u v·ªõi bigram
  async compareSentencesWithBigrams(sentence1, sentence2) {
    await this.initialize();
    
    console.log('\nüîó SO S√ÅNH V·ªöI BIGRAM:');
    console.log('Sentence 1:', sentence1);
    console.log('Sentence 2:', sentence2);
    
    const words1 = vietnameseStopwordService.extractMeaningfulWords(sentence1);
    const words2 = vietnameseStopwordService.extractMeaningfulWords(sentence2);
    
    const bigrams1 = this.createBigrams(words1);
    const bigrams2 = this.createBigrams(words2);
    
    console.log('Bigrams 1:', bigrams1);
    console.log('Bigrams 2:', bigrams2);
    
    const commonBigrams = bigrams1.filter(bigram => bigrams2.includes(bigram));
    const similarity = bigrams1.length > 0 ? (commonBigrams.length / bigrams1.length) * 100 : 0;
    
    console.log('Common bigrams:', commonBigrams);
    console.log('Bigram similarity:', Math.round(similarity) + '%');
    
    return {
      bigrams1,
      bigrams2,
      commonBigrams,
      similarity: Math.round(similarity)
    };
  }
}

// Test ch√≠nh
async function checkWordProcessing() {
  const checker = new WordProcessingChecker();
  
  try {
    // Ki·ªÉm tra c√°ch x·ª≠ l√Ω t·ª´
    await checker.checkWordProcessing();
    
    // So s√°nh 2 c√¢u v·ªõi bigram
    const sentence1 = "Th·ªÉ thao l√† m√¥n ∆∞a th√≠ch c·ªßa m·ªçi ng∆∞·ªùi t√¥i c≈©ng kh√¥ng ƒë·∫∑c bi·ªát";
    const sentence2 = "T√¥i l√† Kh√°nh, t√¥i ∆∞a th√≠ch th·ªÉ thao, ƒë·∫∑c bi·ªát l√† ƒë√° b√≥ng";
    
    await checker.compareSentencesWithBigrams(sentence1, sentence2);
    
    console.log('\nüí° K·∫æT LU·∫¨N:');
    console.log('='.repeat(50));
    console.log('- Ch∆∞∆°ng tr√¨nh hi·ªán t·∫°i x·ª≠ l√Ω theo t·ª´ ƒë∆°n l·∫ª');
    console.log('- Kh√¥ng c√≥ logic t·∫°o bigram/n-gram t·ª± ƒë·ªông');
    console.log('- C√≥ th·ªÉ t·∫°o chunks nh∆∞ng kh√¥ng ph·∫£i bigram');
    console.log('- N·∫øu mu·ªën bigram, c·∫ßn implement th√™m logic');
    
  } catch (error) {
    console.error('‚ùå L·ªói:', error);
  }
}

// Export
module.exports = {
  WordProcessingChecker,
  checkWordProcessing
};

// Ch·∫°y n·∫øu g·ªçi tr·ª±c ti·∫øp
if (require.main === module) {
  checkWordProcessing();
}